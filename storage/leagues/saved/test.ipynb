{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras.utils as utils\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import optuna\n",
    "\n",
    "random_seed = 0\n",
    "tf.random.set_seed(random_seed) \n",
    "one_hot = True\n",
    "num_eval_samples = 50\n",
    "\n",
    "metric_name = 'Accuracy'\n",
    "metric_target = 0\n",
    "\n",
    "n_trials = 100\n",
    "epochs = 80\n",
    "early_stopping_epochs=35,\n",
    "learning_rate_decay_factor=0.2\n",
    "learning_rate_decay_epochs=10\n",
    "min_layers=3\n",
    "max_layers=5\n",
    "min_units=32\n",
    "max_units=128\n",
    "units_increment=16\n",
    "\n",
    "batch_size = 32\n",
    "input_shape = (19,)\n",
    "noise_range = 0.1992\n",
    "num_hidden_layers = 4\n",
    "hidden_units_list = [32,48,64,80,96,112,128]\n",
    "hidden_layers = [32,80,112,112]\n",
    "batch_normalizations = [False,False,False,False]\n",
    "activations = ['relu', 'gelu','tanh','gelu']\n",
    "regularizations = [ 'l1', 'l1', 'l2', 'l2']\n",
    "dropouts = [0.4,0.2,0.2,0.0]\n",
    "optimizer = 'yogi'\n",
    "learning_rate = 0.0007\n",
    "columnus = ['Season', 'Date', 'Result', 'Home Team', 'Away Team', 'HG', 'AG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_training_dataframe(matches_df: pd.DataFrame, one_hot: bool) -> (np.ndarray, np.ndarray):\n",
    "    inputs = matches_df.dropna().drop(columns=columnus)\n",
    "    inputs = inputs.to_numpy(dtype=np.float64)\n",
    "    targets = matches_df['Season'].replace({\n",
    "            'H' : 0,\n",
    "            'D' : 1,\n",
    "            'A' : 2}).to_numpy(dtype=np.int64)\n",
    "    if one_hot:\n",
    "        targets = utils.to_categorical(targets)\n",
    "    return inputs, targets\n",
    "\n",
    "def split_train_targets(\n",
    "        inputs: np.ndarray,\n",
    "        targets: np.ndarray,\n",
    "        num_eval_samples: int) -> (np.ndarray, np.ndarray, np.ndarray, np.ndarray):\n",
    "    x_train = inputs[num_eval_samples:]\n",
    "    y_train = targets[num_eval_samples:]\n",
    "    x_test = inputs[: num_eval_samples]\n",
    "    y_test = targets[: num_eval_samples]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df = pq.read_table('England.Premier-League.parquet').to_pandas()\n",
    "inputs, targets = preprocess_training_dataframe(matches_df=matches_df, one_hot=one_hot)\n",
    "x_train, y_train, x_test, y_test = split_train_targets(inputs=inputs, targets=targets, num_eval_samples=num_eval_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3009, 19)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3009, 2023)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model() -> float:\n",
    "    optimizer = tfa.optimizers.Yogi(learning_rate=learning_rate)\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape= matches_df.shape[1:]))\n",
    "    model.add(tf.keras.layers.GaussianNoise(stddev=noise_range))\n",
    "    \n",
    "    for i, units in enumerate(hidden_layers):\n",
    "        regularizer = regularizations[i]\n",
    "        batch_norm = batch_normalizations[i]\n",
    "        dropout = dropouts[i]\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "                units=units,\n",
    "                activation=activations[i],\n",
    "                use_bias=not batch_norm,\n",
    "                kernel_regularizer=regularizer))\n",
    "        \n",
    "        if batch_normalizations[i]:\n",
    "            model.add(tf.keras.layers.BatchNormalization())\n",
    "        if dropout > 0.0:\n",
    "            model.add(tf.keras.layers.Dropout(rate=dropout))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(units=3, activation='softmax'))\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(metric_name: str, metric_target: str):\n",
    "    match metric_name:\n",
    "        case 'Accuracy':\n",
    "            metric = lambda y_true, y_pred: accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "        case 'F1':\n",
    "            metric = lambda y_true, y_pred: f1_score(y_true=y_true, y_pred=y_pred, average=None)[metric_target]\n",
    "        case 'Precision':\n",
    "            metric = lambda y_true, y_pred: precision_score(y_true=y_true, y_pred=y_pred, average=None)[metric_target]\n",
    "        case 'Recall':\n",
    "            metric = lambda y_true, y_pred: recall_score(y_true=y_true, y_pred=y_pred, average=None)[metric_target]\n",
    "        case _:\n",
    "            raise NotImplementedError(f'Error: Metric \"{metric_name}\" has not been implemented yet')\n",
    "    \n",
    "    tuner = _construct_tuner(\n",
    "        n_trials=n_trials_var,\n",
    "        metric=metric,\n",
    "        matches_df=matches_df,\n",
    "        num_eval_samples=num_eval_samples_var,\n",
    "        random_seed=random_seed) \n",
    "    best_params = tuner.tune()\n",
    "    \n",
    "    model = construct_model(input_shape=x_train.shape[1:], random_seed=random_seed)\n",
    "    build_model(model=model, best_params=best_params)\n",
    "    eval_metrics = model.train(\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "        x_test=x_test,\n",
    "        y_test=y_test,\n",
    "        use_over_sampling=best_params['user_over_sampling'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-20 17:34:24,422] A new study created in memory with name: no-name-e5ceb769-4186-423c-a5fe-0e157126b0f1\n",
      "[W 2023-08-20 17:34:24,644] Trial 0 failed with parameters: {'user_over_sampling': False} because of the following error: AttributeError(\"'Sequential' object has no attribute 'train'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_3218/3332776971.py\", line 4, in _objective\n",
      "    model.train(\n",
      "AttributeError: 'Sequential' object has no attribute 'train'\n",
      "[W 2023-08-20 17:34:24,645] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[39mreturn\u001b[39;00m _evaluate(y_true\u001b[39m=\u001b[39my_test, y_pred\u001b[39m=\u001b[39my_pred)\n\u001b[1;32m     13\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m study\u001b[39m.\u001b[39;49moptimize(_objective, n_trials\u001b[39m=\u001b[39;49mn_trials)\n\u001b[1;32m     15\u001b[0m best_params \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_trial\u001b[39m.\u001b[39mparams\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py:442\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     _optimize(\n\u001b[1;32m    443\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    444\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    445\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    446\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    447\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    448\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    449\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    450\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    451\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    452\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m, in \u001b[0;36m_objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[39m=\u001b[39m create_model()\n\u001b[1;32m      3\u001b[0m use_over_sampling \u001b[39m=\u001b[39m \u001b[39mbool\u001b[39m(trial\u001b[39m.\u001b[39msuggest_categorical(\u001b[39m'\u001b[39m\u001b[39muser_over_sampling\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m]))\n\u001b[0;32m----> 4\u001b[0m model\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m      5\u001b[0m     x_train\u001b[39m=\u001b[39mx_train,\n\u001b[1;32m      6\u001b[0m     y_train\u001b[39m=\u001b[39my_train,\n\u001b[1;32m      7\u001b[0m     x_test\u001b[39m=\u001b[39mx_test,\n\u001b[1;32m      8\u001b[0m     y_test\u001b[39m=\u001b[39my_test,\n\u001b[1;32m      9\u001b[0m     use_over_sampling\u001b[39m=\u001b[39muse_over_sampling)\n\u001b[1;32m     10\u001b[0m y_pred, _ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(x\u001b[39m=\u001b[39mx_test)\n\u001b[1;32m     11\u001b[0m \u001b[39mreturn\u001b[39;00m _evaluate(y_true\u001b[39m=\u001b[39my_test, y_pred\u001b[39m=\u001b[39my_pred)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'train'"
     ]
    }
   ],
   "source": [
    "def _objective(trial) -> float:\n",
    "    model = create_model()\n",
    "    use_over_sampling = bool(trial.suggest_categorical('user_over_sampling', [True, False]))\n",
    "    model.train(\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "        x_test=x_test,\n",
    "        y_test=y_test,\n",
    "        use_over_sampling=use_over_sampling)\n",
    "    y_pred, _ = model.predict(x=x_test)\n",
    "    return _evaluate(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(_objective, n_trials=n_trials)\n",
    "best_params = study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = _construct_model(input_shape=x_train.shape[1:], random_seed=random_seed)\n",
    "#_build_model(model=model, best_params=best_params)\n",
    "#eval_metrics = model.train(x_train=x_train,y_train=y_train,x_test=x_test,y_test=y_test,use_over_sampling=best_params['user_over_sampling'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
